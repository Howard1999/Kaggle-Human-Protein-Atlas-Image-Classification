{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "realistic-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 292/292 [00:35<00:00,  8.33it/s]\n",
      "5it [00:00, 49.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.324\n",
      "1 0.057999999999999996\n",
      "2 0.264\n",
      "3 0.406\n",
      "4 0.74\n",
      "5 0.314\n",
      "6 0.448\n",
      "7 0.09999999999999999\n",
      "8 0.838\n",
      "9 0.5539999999999999\n",
      "10 0.8019999999999999\n",
      "11 0.401\n",
      "12 0.422\n",
      "13 0.132\n",
      "14 0.128\n",
      "15 0.05\n",
      "16 0.05199999999999999\n",
      "17 0.09699999999999999\n",
      "18 0.12100000000000001\n",
      "19 0.311\n",
      "20 0.05499999999999999\n",
      "21 0.16799999999999998\n",
      "22 0.311\n",
      "23 0.628\n",
      "24 0.323\n",
      "25 0.433\n",
      "26 0.185\n",
      "27 0.41300000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11703it [04:04, 47.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import Inference\n",
    "import csv\n",
    "import Augmentation\n",
    "import Model\n",
    "import torch\n",
    "import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from Dataset import _read_image\n",
    "from Metrics import find_threshold\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda:0')\n",
    "# path\n",
    "dataset_path = '/mnt/train-data1/howard/cvfinal/human-protein-atlas-image-classification/'\n",
    "model_path = '/mnt/train-data1/howard/cvfinal/model/v5/epoch14.pth'\n",
    "# transform\n",
    "eval_transform = Augmentation.get_eval_transform()\n",
    "# load validation set\n",
    "_, validation_dataset = Dataset.get_train_val_dataset(dataset_path + 'train.csv',\n",
    "                                                      28, img_folder=dataset_path + 'train/', \n",
    "                                                      transform=eval_transform)\n",
    "validation_data_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False, num_workers=36)\n",
    "# model\n",
    "model = Model.get_model(28, model_path)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# find threshold\n",
    "with torch.no_grad():\n",
    "    y_true, y_pred = [], []\n",
    "    for img, _ in tqdm(validation_data_loader):\n",
    "        y_pred.append(model(img.to(device)).to('cpu'))\n",
    "    y_pred = torch.sigmoid(torch.cat(y_pred))\n",
    "    threshold = find_threshold(y_pred)\n",
    "    for i, thr in enumerate(threshold):\n",
    "        print(i, thr)\n",
    "\n",
    "# test\n",
    "output_str = 'Id,Predicted\\n'\n",
    "test_csv = dataset_path + 'sample_submission.csv'\n",
    "with open(test_csv, newline='') as fp:\n",
    "    rows = csv.reader(fp)\n",
    "    first_row = True\n",
    "    for row in tqdm(rows):\n",
    "        if first_row:\n",
    "            first_row = False\n",
    "            continue\n",
    "            \n",
    "        image_id = row[0]\n",
    "        img = eval_transform(_read_image(image_id, dataset_path + 'test/'))\n",
    "        label = Inference.inference(model, img, device=device, threshold=threshold)\n",
    "        label = [str(l) for l in label]\n",
    "        \n",
    "        output_str += image_id + ',' + ' '.join(label) + '\\n'\n",
    "with open('output.csv', 'w') as fp:\n",
    "    fp.write(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-profit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
